"""ä»£ç å®¡æŸ¥å™¨"""
from typing import Dict, List, Any, Optional
import logging
import re
import asyncio
from urllib.parse import urlparse
import subprocess
import tempfile
import os
from pathlib import Path

from .base import BaseEvaluator, EvaluatorError
from ..models.assessment import CodeScore
from ..config.settings import get_prompts
from ..services.code_analyzer import EnhancedCodeAnalyzer


logger = logging.getLogger(__name__)


class CodeReviewer(BaseEvaluator):
    """ä»£ç å®¡æŸ¥å™¨"""
    
    def __init__(self):
        super().__init__()
        self.prompts = get_prompts()
        self.code_analyzer = EnhancedCodeAnalyzer()
    
    async def evaluate(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è¯„ä¼°ä»£ç è´¨é‡
        
        Args:
            data: åŒ…å«ä»£ç ä¿¡æ¯çš„å­—å…¸
                - repo_url: ä»£ç ä»“åº“é“¾æ¥
                - language: ä¸»è¦ç¼–ç¨‹è¯­è¨€
                - framework: ä½¿ç”¨çš„æ¡†æ¶
                - lines_of_code: ä»£ç è¡Œæ•°
                - test_coverage: æµ‹è¯•è¦†ç›–ç‡
                - code_snippets: ä»£ç ç‰‡æ®µ
                
        Returns:
            è¯„ä¼°ç»“æœå­—å…¸
        """
        try:
            logger.info(f"ğŸ” ä»£ç è¯„ä¼°å™¨å¼€å§‹è¯„ä¼°:")
            logger.info(f"    æ¥æ”¶åˆ°çš„æ•°æ®é”®: {list(data.keys())}")
            
            # æå–æ•°æ®
            repo_url = data.get("code_repo", data.get("repo_url", ""))
            language = data.get("language", "æœªæŒ‡å®š")
            framework = data.get("framework", "æœªæŒ‡å®š")
            lines_of_code = data.get("lines_of_code", 0)
            test_coverage = data.get("test_coverage", 0.0)
            code_snippets = data.get("code_snippets", [])
            
            logger.info(f"    ä»£ç ä»“åº“: {repo_url}")
            logger.info(f"    ç¼–ç¨‹è¯­è¨€: {language}")
            logger.info(f"    æ¡†æ¶: {framework}")
            logger.info(f"    ä»£ç è¡Œæ•°: {lines_of_code}")
            logger.info(f"    ä»£ç ç‰‡æ®µæ•°é‡: {len(code_snippets)}")
            if code_snippets:
                logger.info(f"    ä»£ç ç‰‡æ®µæ–‡ä»¶: {list(code_snippets.keys()) if isinstance(code_snippets, dict) else 'åˆ—è¡¨æ ¼å¼'}")
            
            if not repo_url and not code_snippets:
                logger.error("âŒ ç¼ºå°‘ä»£ç ä»“åº“é“¾æ¥æˆ–ä»£ç ç‰‡æ®µ")
                raise EvaluatorError("ç¼ºå°‘ä»£ç ä»“åº“é“¾æ¥æˆ–ä»£ç ç‰‡æ®µ")
            
            # ä»£ç é™æ€åˆ†æ
            code_analysis = await self._analyze_code(repo_url, code_snippets, language)
            
            # å¦‚æœæœ‰å®Œæ•´é¡¹ç›®è·¯å¾„ï¼Œè¿›è¡Œæ·±åº¦åˆ†æ
            enhanced_analysis = None
            if repo_url and Path(repo_url).exists():
                try:
                    enhanced_analysis = await self.code_analyzer.analyze_project(repo_url)
                except Exception as e:
                    logger.warning(f"å¢å¼ºåˆ†æå¤±è´¥: {str(e)}")
            
            # è·å–ä»»åŠ¡ä¿¡æ¯
            task_requirements = data.get("task_requirements", [])
            task_deliverables = data.get("task_deliverables", [])
            
            # æ„å»ºè¯¦ç»†çš„æç¤ºè¯
            prompt = f"""
è¯·å¯¹ä»¥ä¸‹ä»£ç è¿›è¡Œè´¨é‡è¯„ä¼°ï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ç»“æœï¼š

ä»£ç æ¥æº: {repo_url or "ä»£ç ç‰‡æ®µæäº¤"}
ç¼–ç¨‹è¯­è¨€: {language}
ä½¿ç”¨æ¡†æ¶: {framework}
ä»£ç è¡Œæ•°: {lines_of_code}
æµ‹è¯•è¦†ç›–ç‡: {test_coverage}%

ä»£ç åˆ†æç»“æœ: {code_analysis}

"""
            
            # ğŸ”¥ æ·»åŠ ä»»åŠ¡è¦æ±‚
            if task_requirements:
                requirements_text = "\n".join([f"{i+1}. {req}" for i, req in enumerate(task_requirements)])
                deliverables_text = "\n".join([f"{i+1}. {req}" for i, req in enumerate(task_deliverables)])
                prompt += f"""
ã€ä»»åŠ¡è¦æ±‚ã€‘
{requirements_text}

ã€æäº¤è¦æ±‚ã€‘
{deliverables_text}

"""
            
            # æ·»åŠ ä»£ç ç‰‡æ®µ
            if code_snippets:
                prompt += "ä»£ç ç‰‡æ®µ:\n"
                for i, snippet in enumerate(code_snippets[:3]):  # æœ€å¤šåˆ†æå‰3ä¸ªç‰‡æ®µ
                    prompt += f"\nç‰‡æ®µ{i+1}:\n```{language}\n{snippet[:500]}...\n```\n"
            
            prompt += """
è¯·ä»ä»¥ä¸‹ç»´åº¦è¯„ä¼°ï¼ˆæ¯ä¸ªç»´åº¦0-100åˆ†ï¼‰ï¼š

1. æ­£ç¡®æ€§ (correctness): è¯­æ³•æ­£ç¡®ã€é€»è¾‘å®Œæ•´ã€é”™è¯¯å¤„ç†
2. å¯è¯»æ€§ (readability): å‘½åè§„èŒƒã€ä»£ç ç»“æ„ã€æ³¨é‡Šè´¨é‡  
3. æ¶æ„ (architecture): æ¨¡å—åŒ–è®¾è®¡ã€è®¾è®¡æ¨¡å¼ã€æ¥å£è®¾è®¡
4. æ€§èƒ½ (performance): ç®—æ³•æ•ˆç‡ã€èµ„æºä½¿ç”¨ã€å®‰å…¨è€ƒè™‘

ğŸ”¥ ä¸¥æ ¼è¯„ä¼°æ ‡å‡†ï¼š
- å¦‚æœã€æäº¤è¦æ±‚ã€‘è¦æ±‚æäº¤ç‰¹å®šææ–™ï¼ˆå¦‚ä¼˜åŒ–æŠ¥å‘Šã€å‹æµ‹ç»“æœã€éƒ¨ç½²æ–¹æ¡ˆç­‰ï¼‰ï¼Œè¯·æ£€æŸ¥æäº¤çš„ä»£ç ç‰‡æ®µæ˜¯å¦åŒ…å«è¿™äº›å†…å®¹
- å¦‚æœå­¦ç”Ÿæœªæäº¤è¦æ±‚çš„ææ–™ï¼Œè¯¥ç»´åº¦è¯„åˆ†å¿…é¡»é™ä½è‡³60åˆ†ä»¥ä¸‹
- å¦‚æœä»»åŠ¡è¦æ±‚ç‰¹å®šåŠŸèƒ½ï¼ˆå¦‚GPUåŠ é€Ÿã€å¹¶å‘å¤„ç†ã€æ€§èƒ½æµ‹è¯•ç­‰ï¼‰ï¼Œä»£ç ä¸­å¿…é¡»èƒ½æ˜ç¡®çœ‹åˆ°è¿™äº›åŠŸèƒ½çš„å®ç°
- å¦‚æœä»£ç ä¸­æ²¡æœ‰å®ç°ä»»åŠ¡è¦æ±‚çš„åŠŸèƒ½ï¼Œè¯·åœ¨feedbackä¸­æ˜ç¡®æŒ‡å‡ºç¼ºå¤±çš„åŠŸèƒ½ç‚¹
- æ ¹æ®ä»£ç å®ç°çš„åŠŸèƒ½å®Œæ•´æ€§ç»™å‡ºç›¸åº”è¯„åˆ†ï¼Œä¸è¦å‡è®¾å­¦ç”Ÿåšäº†æœªæäº¤çš„å†…å®¹

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼ˆä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šï¼‰ï¼š
{
    "correctness": æ•°å­—è¯„åˆ†,
    "readability": æ•°å­—è¯„åˆ†,
    "architecture": æ•°å­—è¯„åˆ†,
    "performance": æ•°å­—è¯„åˆ†,
    "feedback": "è¯¦ç»†åé¦ˆæ–‡å­—ï¼ˆå¿…é¡»ç»“åˆä»»åŠ¡è¦æ±‚è¯„ä»·ï¼‰",
    "suggestions": ["å»ºè®®1", "å»ºè®®2"],
    "resources": ["æ¨èèµ„æº1", "æ¨èèµ„æº2"]
}
"""
            
            # å¦‚æœæœ‰å¢å¼ºåˆ†æï¼Œæ·»åŠ åˆ°æç¤ºè¯
            if enhanced_analysis:
                enhanced_prompt = self._build_enhanced_prompt(prompt, enhanced_analysis)
            else:
                enhanced_prompt = prompt
            
            # è°ƒç”¨AIè¿›è¡Œè¯„ä¼°
            logger.info("å¼€å§‹è¯„ä¼°ä»£ç è´¨é‡...")
            response = await self._call_ai_api(enhanced_prompt, max_tokens=2000)
            
            try:
                result = self._parse_json_response(response)
            except Exception as e:
                logger.error(f"ä»£ç è¯„ä¼°å“åº”è§£æå¤±è´¥: {str(e)}")
                # è¿”å›é»˜è®¤è¯„ä¼°ç»“æœ
                result = {
                    "correctness": 70,
                    "readability": 70,
                    "architecture": 70,
                    "performance": 70,
                    "feedback": "AIå“åº”è§£æå¤±è´¥ï¼Œç»™äºˆé»˜è®¤è¯„åˆ†",
                    "suggestions": ["è¯·æ£€æŸ¥ä»£ç è´¨é‡"],
                    "resources": ["ä»£ç è§„èŒƒæ–‡æ¡£"]
                }
            
            # éªŒè¯å’Œå¤„ç†è¯„åˆ†
            correctness_score = self._validate_score(result.get("correctness", 0))
            readability_score = self._validate_score(result.get("readability", 0))
            architecture_score = self._validate_score(result.get("architecture", 0))
            performance_score = self._validate_score(result.get("performance", 0))
            
            code_score = CodeScore(
                correctness=correctness_score,
                readability=readability_score,
                architecture=architecture_score,
                performance=performance_score
            )
            
            # ç”Ÿæˆè¯Šæ–­ä¿¡æ¯
            feedback = result.get("feedback", "")
            suggestions = result.get("suggestions", [])
            issues = result.get("issues", [])
            
            diagnoses = self._generate_code_diagnoses(code_score, issues, test_coverage)
            
            # æ¨èå­¦ä¹ èµ„æº
            resources = self._recommend_code_resources(code_score, language, framework)
            
            logger.info(f"ä»£ç è¯„ä¼°å®Œæˆï¼Œæ€»åˆ†: {code_score.overall}")
            
            return {
                "score": code_score,
                "overall_score": code_score.overall,
                "diagnoses": diagnoses,
                "resources": resources,
                "feedback": feedback,
                "code_analysis": code_analysis,
                "enhanced_analysis": enhanced_analysis,
                "issues": issues,
                "raw_result": result
            }
            
        except Exception as e:
            logger.error(f"ä»£ç è¯„ä¼°å¤±è´¥: {str(e)}")
            raise EvaluatorError(f"ä»£ç è¯„ä¼°å¤±è´¥: {str(e)}")
    
    async def _analyze_code(self, repo_url: str, code_snippets: List[str], 
                           language: str) -> str:
        """
        åˆ†æä»£ç 
        
        Args:
            repo_url: ä»£ç ä»“åº“é“¾æ¥
            code_snippets: ä»£ç ç‰‡æ®µ
            language: ç¼–ç¨‹è¯­è¨€
            
        Returns:
            ä»£ç åˆ†æç»“æœ
        """
        analysis_results = []
        
        # åˆ†æä»£ç ç‰‡æ®µ
        if code_snippets:
            snippet_analysis = self._analyze_code_snippets(code_snippets, language)
            analysis_results.append(f"ä»£ç ç‰‡æ®µåˆ†æ: {snippet_analysis}")
        
        # å¦‚æœæœ‰ä»“åº“é“¾æ¥ï¼Œå°è¯•è¿›è¡Œæ›´æ·±å…¥çš„åˆ†æ
        if repo_url:
            repo_analysis = await self._analyze_repository(repo_url)
            if repo_analysis:
                analysis_results.append(f"ä»“åº“åˆ†æ: {repo_analysis}")
        
        return "\n".join(analysis_results)
    
    def _analyze_code_snippets(self, code_snippets: List[str], language: str) -> str:
        """åˆ†æä»£ç ç‰‡æ®µ"""
        analysis = []
        
        for i, snippet in enumerate(code_snippets):
            snippet_analysis = []
            
            # åŸºæœ¬ç»Ÿè®¡
            lines = snippet.split('\n')
            non_empty_lines = [line for line in lines if line.strip()]
            snippet_analysis.append(f"è¡Œæ•°: {len(non_empty_lines)}")
            
            # æ³¨é‡Šç‡åˆ†æ
            comment_lines = self._count_comment_lines(snippet, language)
            comment_ratio = comment_lines / len(non_empty_lines) if non_empty_lines else 0
            snippet_analysis.append(f"æ³¨é‡Šç‡: {comment_ratio:.1%}")
            
            # å¤æ‚åº¦åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
            complexity = self._estimate_complexity(snippet)
            snippet_analysis.append(f"å¤æ‚åº¦: {complexity}")
            
            # å‘½åè§„èŒƒæ£€æŸ¥
            naming_issues = self._check_naming_conventions(snippet, language)
            if naming_issues:
                snippet_analysis.append(f"å‘½åé—®é¢˜: {len(naming_issues)}ä¸ª")
            
            analysis.append(f"ç‰‡æ®µ{i+1}: {', '.join(snippet_analysis)}")
        
        return "; ".join(analysis)
    
    async def _analyze_repository(self, repo_url: str) -> Optional[str]:
        """åˆ†æä»£ç ä»“åº“ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        try:
            # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„ä»“åº“åˆ†æé€»è¾‘
            # ä¾‹å¦‚å…‹éš†ä»“åº“ã€è¿è¡Œé™æ€åˆ†æå·¥å…·ç­‰
            
            # ä»URLæ¨æ–­ä¸€äº›ä¿¡æ¯
            parsed_url = urlparse(repo_url)
            if "github.com" in parsed_url.netloc:
                return "GitHubä»“åº“ï¼Œå»ºè®®æ£€æŸ¥READMEã€æµ‹è¯•æ–‡ä»¶å’ŒCIé…ç½®"
            elif "gitlab.com" in parsed_url.netloc:
                return "GitLabä»“åº“ï¼Œå»ºè®®æ£€æŸ¥é¡¹ç›®ç»“æ„å’Œæ–‡æ¡£"
            else:
                return "ä»£ç ä»“åº“é“¾æ¥æœ‰æ•ˆ"
                
        except Exception as e:
            logger.warning(f"ä»“åº“åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def _count_comment_lines(self, code: str, language: str) -> int:
        """ç»Ÿè®¡æ³¨é‡Šè¡Œæ•°"""
        lines = code.split('\n')
        comment_count = 0
        
        for line in lines:
            stripped = line.strip()
            if not stripped:
                continue
                
            # æ ¹æ®è¯­è¨€åˆ¤æ–­æ³¨é‡Š
            if language.lower() in ['python']:
                if stripped.startswith('#') or stripped.startswith('"""') or stripped.startswith("'''"):
                    comment_count += 1
            elif language.lower() in ['javascript', 'typescript', 'java', 'c++', 'c']:
                if stripped.startswith('//') or stripped.startswith('/*') or stripped.startswith('*'):
                    comment_count += 1
            elif language.lower() in ['html']:
                if '<!--' in stripped:
                    comment_count += 1
        
        return comment_count
    
    def _estimate_complexity(self, code: str) -> str:
        """ä¼°ç®—ä»£ç å¤æ‚åº¦"""
        # ç®€åŒ–çš„å¤æ‚åº¦è¯„ä¼°
        complexity_keywords = [
            'if', 'else', 'elif', 'for', 'while', 'try', 'except', 'finally',
            'switch', 'case', 'catch', 'loop'
        ]
        
        complexity_count = sum(code.lower().count(keyword) for keyword in complexity_keywords)
        
        if complexity_count < 3:
            return "ä½"
        elif complexity_count < 8:
            return "ä¸­ç­‰"
        else:
            return "é«˜"
    
    def _check_naming_conventions(self, code: str, language: str) -> List[str]:
        """æ£€æŸ¥å‘½åè§„èŒƒ"""
        issues = []
        
        # ç®€åŒ–çš„å‘½åæ£€æŸ¥
        if language.lower() == 'python':
            # æ£€æŸ¥å‡½æ•°åæ˜¯å¦ä½¿ç”¨snake_case
            func_pattern = r'def\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
            functions = re.findall(func_pattern, code)
            for func in functions:
                if not re.match(r'^[a-z_][a-z0-9_]*$', func):
                    issues.append(f"å‡½æ•°å '{func}' ä¸ç¬¦åˆsnake_caseè§„èŒƒ")
        
        elif language.lower() in ['javascript', 'typescript']:
            # æ£€æŸ¥å‡½æ•°åæ˜¯å¦ä½¿ç”¨camelCase
            func_pattern = r'function\s+([a-zA-Z_][a-zA-Z0-9_]*)\s*\('
            functions = re.findall(func_pattern, code)
            for func in functions:
                if not re.match(r'^[a-z][a-zA-Z0-9]*$', func):
                    issues.append(f"å‡½æ•°å '{func}' ä¸ç¬¦åˆcamelCaseè§„èŒƒ")
        
        return issues
    
    def _generate_code_diagnoses(self, score: CodeScore, issues: List[str], 
                                test_coverage: float) -> List:
        """ç”Ÿæˆä»£ç è¯Šæ–­ä¿¡æ¯"""
        diagnoses = []
        
        if score.correctness < 70:
            diagnoses.extend(self._generate_diagnosis(
                "code.correctness",
                ["ä»£ç æ­£ç¡®æ€§å’Œå¥å£®æ€§ä¸è¶³"] + issues[:2],
                ["å¢åŠ å•å…ƒæµ‹è¯•ï¼Œæé«˜æµ‹è¯•è¦†ç›–ç‡è‡³80%ä»¥ä¸Š", "å®Œå–„é”™è¯¯å¤„ç†æœºåˆ¶"]
            ))
        
        if score.readability < 70:
            diagnoses.extend(self._generate_diagnosis(
                "code.readability",
                ["ä»£ç å¯è¯»æ€§å’Œå¯ç»´æŠ¤æ€§æœ‰å¾…æå‡"],
                ["æ”¹è¿›å˜é‡å’Œå‡½æ•°å‘½å", "å¢åŠ å¿…è¦çš„ä»£ç æ³¨é‡Š", "é‡æ„å¤æ‚çš„ä»£ç ç»“æ„"]
            ))
        
        if score.architecture < 70:
            diagnoses.extend(self._generate_diagnosis(
                "code.architecture",
                ["ä»£ç æ¶æ„å’Œè®¾è®¡æ¨¡å¼ä½¿ç”¨ä¸å½“"],
                ["é‡‡ç”¨åˆé€‚çš„è®¾è®¡æ¨¡å¼", "æé«˜ä»£ç æ¨¡å—åŒ–ç¨‹åº¦", "æ”¹è¿›æ¥å£è®¾è®¡"]
            ))
        
        if score.performance < 70:
            diagnoses.extend(self._generate_diagnosis(
                "code.performance",
                ["æ€§èƒ½å’Œå®‰å…¨æ€§å­˜åœ¨é—®é¢˜"],
                ["ä¼˜åŒ–ç®—æ³•å¤æ‚åº¦", "å‡å°‘èµ„æºå ç”¨", "åŠ å¼ºå®‰å…¨æ€§æ£€æŸ¥"]
            ))
        
        # æµ‹è¯•è¦†ç›–ç‡ç›¸å…³è¯Šæ–­
        if test_coverage < 80:
            diagnoses.extend(self._generate_diagnosis(
                "code.tests",
                [f"æµ‹è¯•è¦†ç›–ç‡åä½ï¼ˆå½“å‰{test_coverage}%ï¼‰"],
                ["ç¼–å†™æ›´å¤šå•å…ƒæµ‹è¯•ï¼Œç›®æ ‡è¦†ç›–ç‡â‰¥80%"]
            ))
        
        return diagnoses
    
    def _recommend_code_resources(self, score: CodeScore, language: str, 
                                 framework: str) -> List[str]:
        """æ¨èä»£ç å­¦ä¹ èµ„æº"""
        resources = []
        
        if score.correctness < 80:
            resources.extend([
                f"{language}å•å…ƒæµ‹è¯•æœ€ä½³å®è·µ",
                "é”™è¯¯å¤„ç†ä¸å¼‚å¸¸ç®¡ç†æŒ‡å—",
                "ä»£ç è°ƒè¯•æŠ€å·§ä¸å·¥å…·"
            ])
        
        if score.readability < 80:
            resources.extend([
                f"{language}ç¼–ç è§„èŒƒä¸é£æ ¼æŒ‡å—",
                "ä»£ç é‡æ„æŠ€å·§",
                "ä»£ç æ³¨é‡Šæœ€ä½³å®è·µ"
            ])
        
        if score.architecture < 80:
            resources.extend([
                "è®¾è®¡æ¨¡å¼å®æˆ˜æ•™ç¨‹",
                f"{language}é¡¹ç›®æ¶æ„è®¾è®¡",
                "è½¯ä»¶æ¶æ„åŸåˆ™ä¸å®è·µ"
            ])
        
        if score.performance < 80:
            resources.extend([
                f"{language}æ€§èƒ½ä¼˜åŒ–æŒ‡å—",
                "ç®—æ³•ä¸æ•°æ®ç»“æ„ä¼˜åŒ–",
                "ä»£ç å®‰å…¨æœ€ä½³å®è·µ"
            ])
        
        # æ¡†æ¶ç›¸å…³èµ„æº
        if framework and framework != "æœªæŒ‡å®š":
            resources.append(f"{framework}æ¡†æ¶æœ€ä½³å®è·µ")
        
        return list(set(resources))  # å»é‡
    
    def _build_enhanced_prompt(self, base_prompt: str, enhanced_analysis: dict) -> str:
        """æ„å»ºåŒ…å«å¢å¼ºåˆ†æçš„æç¤ºè¯"""
        enhancement_text = "\n\n=== æ·±åº¦ä»£ç åˆ†æç»“æœ ===\n"
        
        # æ·»åŠ æ•´ä½“æŒ‡æ ‡
        metrics = enhanced_analysis.get("overall_metrics", {})
        if hasattr(metrics, 'lines_of_code'):
            enhancement_text += f"æ€»ä»£ç è¡Œæ•°: {metrics.lines_of_code}\n"
            enhancement_text += f"æ³¨é‡Šè¡Œæ•°: {metrics.comment_lines}\n"
            enhancement_text += f"å¤æ‚åº¦: {metrics.complexity}\n"
        
        # æ·»åŠ æ¶æ„åˆ†æ
        arch = enhanced_analysis.get("architecture_analysis", {})
        if arch.get("structure_score"):
            enhancement_text += f"æ¶æ„è¯„åˆ†: {arch['structure_score']:.1f}/100\n"
            enhancement_text += f"æ¨¡å—åŒ–è¯„åˆ†: {arch.get('modularity_score', 0):.1f}/100\n"
        
        # æ·»åŠ æœ€ä½³å®è·µæ£€æŸ¥
        bp = enhanced_analysis.get("best_practices", {})
        if bp.get("score"):
            enhancement_text += f"æœ€ä½³å®è·µè¯„åˆ†: {bp['score']:.1f}/100\n"
            checklist = bp.get("checklist", {})
            enhancement_text += f"é¡¹ç›®æ–‡æ¡£å®Œæ•´æ€§: {'æ˜¯' if checklist.get('has_readme') else 'å¦'}\n"
            enhancement_text += f"åŒ…å«æµ‹è¯•: {'æ˜¯' if checklist.get('has_tests') else 'å¦'}\n"
        
        # æ·»åŠ ä¸»è¦é—®é¢˜
        issues = enhanced_analysis.get("issues", [])
        if issues:
            enhancement_text += f"\nå‘ç°çš„ä¸»è¦é—®é¢˜:\n"
            for issue in issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
                if hasattr(issue, 'message'):
                    enhancement_text += f"- {issue.message} (ä¸¥é‡ç¨‹åº¦: {issue.severity})\n"
        
        # æ·»åŠ å»ºè®®
        recommendations = enhanced_analysis.get("recommendations", [])
        if recommendations:
            enhancement_text += f"\nä¸»è¦å»ºè®®:\n"
            for rec in recommendations[:3]:  # æ˜¾ç¤ºå‰3ä¸ªå»ºè®®
                enhancement_text += f"- {rec}\n"
        
        return base_prompt + enhancement_text + "\n\nè¯·åŸºäºä»¥ä¸Šæ·±åº¦åˆ†æç»“æœç»™å‡ºæ›´å‡†ç¡®çš„è¯„ä¼°ã€‚"


class CodeAnalysisError(EvaluatorError):
    """ä»£ç åˆ†æé”™è¯¯"""
    pass


