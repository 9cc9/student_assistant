"""è¯„ä¼°æœåŠ¡æ ¸å¿ƒå®ç°"""
import asyncio
import logging
from typing import Dict, Any, Optional, List
from datetime import datetime
import uuid

from ..services.db_service import AssessmentDBService
from ..services.assessment_rule_service import get_assessment_rule_service

from ..models.assessment import (
    Assessment, AssessmentStatus, Deliverables, ScoreBreakdown
)
from ..models.submission import Submission, IdeaDescription, UIDesign, CodeRepository
from ..evaluators.idea_evaluator import IdeaEvaluator
from ..evaluators.ui_analyzer import UIAnalyzer
from ..evaluators.code_reviewer import CodeReviewer
from ..evaluators.score_aggregator import ScoreAggregator
from ..config.settings import assessment_config, path_config
from .learning_path_service import LearningPathService
from ..models.learning_path import NodeStatus


logger = logging.getLogger(__name__)


class AssessmentService:
    """è¯„ä¼°æœåŠ¡ç±»ï¼Œè´Ÿè´£åè°ƒæ•´ä¸ªè¯„ä¼°æµç¨‹"""
    
    def __init__(self):
        if not hasattr(self, '_initialized'):
            self.config = assessment_config
            self.idea_evaluator = IdeaEvaluator()
            self.ui_analyzer = UIAnalyzer()
            self.code_reviewer = CodeReviewer()
            self.score_aggregator = ScoreAggregator()
            self.learning_path_service = LearningPathService()
            self.db_service = AssessmentDBService()
            self.rule_service = get_assessment_rule_service()
            
            self._initialized = True
            
        # å®Œå…¨ä½¿ç”¨æ•°æ®åº“å­˜å‚¨ï¼Œç§»é™¤æ–‡ä»¶å­˜å‚¨ä¾èµ–
        
        # ç¡®ä¿å­¦ä¹ è·¯å¾„æœåŠ¡å¯ç”¨
        if not hasattr(self, 'learning_path_service'):
            self.learning_path_service = LearningPathService()
    
    async def submit_assessment(self, student_id: str, deliverables: Dict[str, Any]) -> str:
        """
        æäº¤è¯„ä¼°è¯·æ±‚
        
        Args:
            student_id: å­¦ç”ŸID
            deliverables: æäº¤ç‰©æ•°æ®
            
        Returns:
            è¯„ä¼°ID
        """
        try:
            # ç”Ÿæˆè¯„ä¼°ID
            assessment_id = f"a_{datetime.now().strftime('%y%m%d')}_{str(uuid.uuid4())[:8]}"
            
            # è§£ææäº¤ç‰©
            parsed_deliverables = self._parse_deliverables(deliverables)
            
            # è·å–è¯„åˆ†è§„åˆ™
            rule = self.rule_service.get_default_rule()
            if not rule:
                raise AssessmentServiceError("æ— æ³•è·å–é»˜è®¤è¯„åˆ†è§„åˆ™")
            
            # åˆ›å»ºè¯„ä¼°æ‰§è¡Œè®°å½•ï¼ˆAssessmentRunæ˜¯å…·ä½“çš„è¯„ä¼°æ‰§è¡Œè®°å½•ï¼‰
            assessment_run_data = {
                'run_id': assessment_id,  # ä½¿ç”¨ç›¸åŒçš„ID
                'student_id': student_id,
                'assessment_id': rule['rule_id'],  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¯„åˆ†è§„åˆ™ID
                'node_id': rule.get('node_id', 'file_upload'),
                'channel': rule.get('channel', 'B'),
                'status': 'queued',
                'created_at': datetime.now()
            }
            
            # å­˜å‚¨åˆ°æ•°æ®åº“
            self.db_service.create_assessment_run(assessment_run_data)
            logger.info(f"ğŸ“‹ âœ… è¯„ä¼°è®°å½•å·²å­˜å‚¨åˆ°æ•°æ®åº“: {assessment_id}")
            
            # åŒæ­¥æ‰§è¡Œè¯„ä¼°ï¼ˆé¿å…å¼‚æ­¥ä»»åŠ¡é—®é¢˜ï¼‰
            try:
                import threading
                def run_assessment():
                    import asyncio
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    try:
                        loop.run_until_complete(self._execute_assessment(assessment_id))
                    finally:
                        loop.close()
                
                # åœ¨åå°çº¿ç¨‹ä¸­æ‰§è¡Œè¯„ä¼°
                thread = threading.Thread(target=run_assessment, daemon=True)
                thread.start()
                logger.info(f"ğŸ“‹ ğŸš€ è¯„ä¼°ä»»åŠ¡å·²åœ¨åå°çº¿ç¨‹ä¸­å¯åŠ¨: {assessment_id}")
            except Exception as e:
                logger.error(f"ğŸ“‹ âŒ å¯åŠ¨è¯„ä¼°ä»»åŠ¡å¤±è´¥: {str(e)}")
                # å¦‚æœåå°æ‰§è¡Œå¤±è´¥ï¼Œè‡³å°‘æ›´æ–°çŠ¶æ€ä¸ºå¤±è´¥
                try:
                    self.db_service.update_assessment_run(assessment_id, {
                        'status': 'failed',
                        'error_message': f'å¯åŠ¨è¯„ä¼°ä»»åŠ¡å¤±è´¥: {str(e)}',
                        'updated_at': datetime.utcnow()
                    })
                except:
                    pass
            
            logger.info(f"è¯„ä¼°è¯·æ±‚å·²æäº¤ï¼ŒID: {assessment_id}")
            return assessment_id
            
        except Exception as e:
            logger.error(f"æäº¤è¯„ä¼°å¤±è´¥: {str(e)}")
            raise AssessmentServiceError(f"æäº¤è¯„ä¼°å¤±è´¥: {str(e)}")
    
    def get_assessment_status(self, assessment_id: str) -> Dict[str, Any]:
        """
        è·å–è¯„ä¼°çŠ¶æ€
        
        Args:
            assessment_id: è¯„ä¼°ID
            
        Returns:
            è¯„ä¼°çŠ¶æ€ä¿¡æ¯
        """
        logger.info(f"ğŸ“‹ ğŸ” æŸ¥è¯¢è¯„ä¼°è®°å½•: {assessment_id}")
        
        # ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•
        try:
            assessment_run = self.db_service.get_assessment_run(assessment_id)
            if not assessment_run:
                logger.error(f"ğŸ“‹ âŒ è¯„ä¼°è®°å½•ä¸å­˜åœ¨: {assessment_id}")
                raise AssessmentServiceError(f"è¯„ä¼°è®°å½•ä¸å­˜åœ¨: {assessment_id}")
            
            # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
            assessment = {
                "assessment_id": assessment_run['run_id'],
                "student_id": assessment_run['student_id'],
                "status": assessment_run['status'],
                "created_at": assessment_run['created_at'].isoformat() if assessment_run['created_at'] else None,
                "updated_at": assessment_run['updated_at'].isoformat() if assessment_run['updated_at'] else None,
                "overall_score": assessment_run['overall_score'],
                "idea_score": assessment_run['idea_score'],
                "ui_score": assessment_run['ui_score'],
                "code_score": assessment_run['code_score'],
                "detailed_scores": assessment_run['detailed_scores'] or {},
                "diagnosis": assessment_run['diagnosis'] or [],
                "resources": assessment_run['resources'] or [],
                "exit_rules": assessment_run['exit_rules'] or {},
                "error_message": assessment_run['error_message'],
                "started_at": assessment_run['started_at'].isoformat() if assessment_run['started_at'] else None,
                "completed_at": assessment_run['completed_at'].isoformat() if assessment_run['completed_at'] else None
            }
            
            # æ„å»ºbreakdownæ•°æ®
            breakdown_data = {}
            if assessment_run['idea_score'] is not None:
                breakdown_data["idea"] = assessment_run['idea_score']
            if assessment_run['ui_score'] is not None:
                breakdown_data["ui"] = assessment_run['ui_score']
            if assessment_run['code_score'] is not None:
                breakdown_data["code"] = assessment_run['code_score']
            
            # æ·»åŠ è¯¦ç»†å­ç»´åº¦åˆ†æ•°
            if assessment_run['detailed_scores']:
                detailed_scores = assessment_run['detailed_scores']
                if 'idea' in detailed_scores:
                    breakdown_data["idea_detail"] = detailed_scores['idea']
                if 'ui' in detailed_scores:
                    breakdown_data["ui_detail"] = detailed_scores['ui']
                if 'code' in detailed_scores:
                    breakdown_data["code_detail"] = detailed_scores['code']
            
            assessment["breakdown"] = breakdown_data
            
            return assessment
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•å¤±è´¥: {str(e)}")
            raise AssessmentServiceError(f"è·å–è¯„ä¼°è®°å½•å¤±è´¥: {str(e)}")
        
        # å¤„ç†å­—å…¸å’Œå¯¹è±¡ä¸¤ç§æƒ…å†µ
        if isinstance(assessment, dict):
            result = {
                "assessment_id": assessment_id,
                "student_id": assessment.get("student_id"),
                "status": assessment.get("status"),
                "created_at": assessment.get("created_at"),
                "updated_at": assessment.get("updated_at")
            }
            
            # å¦‚æœè¯„ä¼°å®Œæˆï¼Œæ·»åŠ è¯¦ç»†ç»“æœ
            if assessment.get("status") == "completed":
                # æ„å»ºè¯¦ç»†çš„åˆ†æ•°ç»“æ„
                score_breakdown = assessment.get("score_breakdown", {})
                detailed_scores = assessment.get("detailed_scores")
                
                # å¦‚æœæœ‰è¯¦ç»†è¯„åˆ†ï¼Œæå–å­ç»´åº¦åˆ†æ•°
                breakdown_data = {}
                if isinstance(score_breakdown, dict):
                    breakdown_data = score_breakdown
                else:
                    # å¦‚æœæ˜¯å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—å…¸
                    breakdown_data = {
                        "idea": getattr(score_breakdown, 'idea', 0),
                        "ui": getattr(score_breakdown, 'ui', 0), 
                        "code": getattr(score_breakdown, 'code', 0)
                    }
                
                # æ·»åŠ è¯¦ç»†çš„å­ç»´åº¦åˆ†æ•°
                if detailed_scores:
                    if hasattr(detailed_scores, 'idea'):
                        breakdown_data["idea_detail"] = {
                            "innovation": getattr(detailed_scores.idea, 'innovation', breakdown_data.get('idea', 0)),
                            "feasibility": getattr(detailed_scores.idea, 'feasibility', breakdown_data.get('idea', 0)),
                            "learning_value": getattr(detailed_scores.idea, 'learning_value', breakdown_data.get('idea', 0))
                        }
                    if hasattr(detailed_scores, 'ui'):
                        breakdown_data["ui_detail"] = {
                            "compliance": getattr(detailed_scores.ui, 'compliance', breakdown_data.get('ui', 0)),
                            "usability": getattr(detailed_scores.ui, 'usability', breakdown_data.get('ui', 0)),
                            "information_arch": getattr(detailed_scores.ui, 'information_arch', breakdown_data.get('ui', 0))
                        }
                    if hasattr(detailed_scores, 'code'):
                        breakdown_data["code_detail"] = {
                            "correctness": getattr(detailed_scores.code, 'correctness', breakdown_data.get('code', 0)),
                            "readability": getattr(detailed_scores.code, 'readability', breakdown_data.get('code', 0)),
                            "architecture": getattr(detailed_scores.code, 'architecture', breakdown_data.get('code', 0)),
                            "performance": getattr(detailed_scores.code, 'performance', breakdown_data.get('code', 0))
                        }
                
                result.update({
                    "overall_score": assessment.get("overall_score"),
                    "assessment_level": assessment.get("assessment_level"),
                    "breakdown": breakdown_data,
                    "diagnosis": assessment.get("diagnosis", []),
                    "resources": assessment.get("resources", []),
                    "exit_rules": assessment.get("exit_rules"),
                    "completed_at": assessment.get("completed_at")
                })
        else:
            # å¤„ç†Assessmentå¯¹è±¡
            result = {
                "assessment_id": assessment_id,
                "student_id": assessment.student_id,
                "status": assessment.status.value if hasattr(assessment.status, 'value') else assessment.status,
                "created_at": assessment.created_at.isoformat() if hasattr(assessment.created_at, 'isoformat') else assessment.created_at,
                "updated_at": assessment.updated_at.isoformat() if assessment.updated_at and hasattr(assessment.updated_at, 'isoformat') else assessment.updated_at
            }
        
            # å¦‚æœè¯„ä¼°å®Œæˆï¼Œè¿”å›è¯¦ç»†ç»“æœ
            if assessment.status == AssessmentStatus.COMPLETED:
                # æ„å»ºåŸºæœ¬è¯„åˆ†æ•°æ®
                breakdown_data = {}
                if assessment.score_breakdown:
                    breakdown_data = {
                        "idea": assessment.score_breakdown.idea,
                        "ui": assessment.score_breakdown.ui,
                        "code": assessment.score_breakdown.code
                    }
                
                # æ·»åŠ è¯¦ç»†çš„å­ç»´åº¦åˆ†æ•°
                if hasattr(assessment, 'detailed_scores') and assessment.detailed_scores:
                    if hasattr(assessment.detailed_scores, 'idea'):
                        breakdown_data["idea_detail"] = {
                            "innovation": assessment.detailed_scores.idea.innovation,
                            "feasibility": assessment.detailed_scores.idea.feasibility,
                            "learning_value": assessment.detailed_scores.idea.learning_value
                        }
                    if hasattr(assessment.detailed_scores, 'ui'):
                        breakdown_data["ui_detail"] = {
                            "compliance": assessment.detailed_scores.ui.compliance,
                            "usability": assessment.detailed_scores.ui.usability,
                            "information_arch": assessment.detailed_scores.ui.information_arch
                        }
                    if hasattr(assessment.detailed_scores, 'code'):
                        breakdown_data["code_detail"] = {
                            "correctness": assessment.detailed_scores.code.correctness,
                            "readability": assessment.detailed_scores.code.readability,
                            "architecture": assessment.detailed_scores.code.architecture,
                            "performance": assessment.detailed_scores.code.performance
                        }
                
                result.update({
                    "overall_score": assessment.overall_score,
                    "assessment_level": assessment.assessment_level.value if assessment.assessment_level else None,
                    "breakdown": breakdown_data,
                    "diagnosis": [
                        {
                            "dimension": d.dimension,
                            "issue": d.issue,
                            "fix": d.fix,
                            "priority": getattr(d, 'priority', 1)
                        } for d in assessment.diagnosis
                    ],
                    "resources": assessment.resources,
                    "exit_rules": {
                        "pass_status": assessment.exit_rules.pass_status,
                        "path_update": assessment.exit_rules.path_update,
                        "remedy": assessment.exit_rules.remedy
                    } if assessment.exit_rules else None,
                    "completed_at": assessment.completed_at.isoformat() if assessment.completed_at else None
                })
        
        return result
    
    def get_all_assessments(self, student_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        è·å–æ‰€æœ‰è¯„ä¼°è®°å½•
        
        Args:
            student_id: å¯é€‰çš„å­¦ç”ŸIDè¿‡æ»¤
            
        Returns:
            è¯„ä¼°è®°å½•åˆ—è¡¨
        """
        try:
            # ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•
            assessment_runs = self.db_service.get_student_assessment_runs(
                student_id or "", 
                limit=1000  # è·å–è¶³å¤Ÿå¤šçš„è®°å½•
            )
            
            # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
            processed_assessments = []
            for run in assessment_runs:
                # è®¡ç®—ç»¼åˆåˆ†æ•°
                idea_score = float(run['idea_score']) if run['idea_score'] else 0
                ui_score = float(run['ui_score']) if run['ui_score'] else 0
                code_score = float(run['code_score']) if run['code_score'] else 0
                final_score = round((idea_score + ui_score + code_score) / 3, 1) if (idea_score + ui_score + code_score) > 0 else 0
                
                # æ„å»ºscore_breakdown
                score_breakdown = {
                    "idea": idea_score,
                    "ui": ui_score,
                    "code": code_score
                }
                
                assessment_data = {
                    "assessment_id": run['run_id'],
                    "student_id": run['student_id'],
                    "submitted_at": run['created_at'].isoformat() if run['created_at'] else None,
                    "created_at": run['created_at'].isoformat() if run['created_at'] else None,
                    "final_score": final_score,
                    "overall_score": run['overall_score'] if run['overall_score'] else final_score,
                    "status": run['status'],
                    "score_breakdown": score_breakdown,
                    "breakdown": score_breakdown,
                    "detailed_scores": run['detailed_scores'] or {},
                    "diagnosis": run['diagnosis'] or [],
                    "resources": run['resources'] or [],
                    "exit_rules": run['exit_rules'] or {},
                    "comprehensive_feedback": "",
                    "deliverables": {},
                    "raw_data": {
                        "run_id": run['run_id'],
                        "student_id": run['student_id'],
                        "assessment_id": run['assessment_id'],
                        "node_id": run['node_id'],
                        "channel": run['channel'],
                        "status": run['status'],
                        "overall_score": run['overall_score'],
                        "idea_score": idea_score,
                        "ui_score": ui_score,
                        "code_score": code_score,
                        "assessment_level": run['assessment_level'],
                        "created_at": run['created_at'].isoformat() if run['created_at'] else None,
                        "completed_at": run['completed_at'].isoformat() if run['completed_at'] else None
                    }
                }
                processed_assessments.append(assessment_data)
            
            # æŒ‰æ—¶é—´é™åºæ’åº
            processed_assessments.sort(key=lambda x: x['created_at'], reverse=True)
            
            logger.info(f"ğŸ“Š ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•: {len(processed_assessments)} æ¡")
            return processed_assessments
            
        except Exception as e:
            logger.error(f"ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•å¤±è´¥: {str(e)}")
            return []
    
    async def _execute_assessment(self, assessment_id: str):
        """
        å¼‚æ­¥æ‰§è¡Œè¯„ä¼°æµç¨‹
        """
        try:
            # ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•
            assessment_run = self.db_service.get_assessment_run(assessment_id)
            if not assessment_run:
                logger.error(f"ğŸ“‹ âŒ è¯„ä¼°è®°å½•ä¸å­˜åœ¨: {assessment_id}")
                return
            
            # æ›´æ–°çŠ¶æ€åˆ°æ•°æ®åº“
            self.db_service.update_assessment_run(assessment_id, {
                'status': 'in_progress',
                'started_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            })
            
            logger.info(f"ğŸ“‹ ğŸš€ å¼€å§‹æ‰§è¡Œè¯„ä¼°: {assessment_id}")
            
            # æ„å»ºè¯„ä¼°æ•°æ®
            evaluation_data = self._prepare_evaluation_data_from_db(assessment_run)
            logger.info(f"ğŸ“‹ ğŸ“ è¯„ä¼°æ•°æ®å‡†å¤‡å®Œæˆ: {list(evaluation_data.keys())}")
            
            # å¹¶è¡Œæ‰§è¡Œå„ç»´åº¦è¯„ä¼°
            logger.info("ğŸ“‹ ğŸ”€ å¼€å§‹å¹¶è¡Œè¯„ä¼°...")
            
            try:
                idea_task = asyncio.create_task(self.idea_evaluator.evaluate(evaluation_data))
                ui_task = asyncio.create_task(self.ui_analyzer.evaluate(evaluation_data))  
                code_task = asyncio.create_task(self.code_reviewer.evaluate(evaluation_data))
                
                # ç­‰å¾…æ‰€æœ‰è¯„ä¼°å®Œæˆ
                logger.info("ğŸ“‹ â³ ç­‰å¾…è¯„ä¼°ç»“æœ...")
                idea_result, ui_result, code_result = await asyncio.gather(
                    idea_task, ui_task, code_task, return_exceptions=True
                )
                
                logger.info("ğŸ“‹ âœ… æ‰€æœ‰è¯„ä¼°ä»»åŠ¡å®Œæˆ")
                logger.info(f"ğŸ“‹ Ideaè¯„ä¼°ç»“æœç±»å‹: {type(idea_result)}")
                logger.info(f"ğŸ“‹ UIè¯„ä¼°ç»“æœç±»å‹: {type(ui_result)}")
                logger.info(f"ğŸ“‹ ä»£ç è¯„ä¼°ç»“æœç±»å‹: {type(code_result)}")
                
            except Exception as e:
                logger.error(f"ğŸ“‹ âŒ å¹¶è¡Œè¯„ä¼°è¿‡ç¨‹å¤±è´¥: {str(e)}")
                raise
            
            # æ£€æŸ¥è¯„ä¼°ç»“æœ
            if isinstance(idea_result, Exception):
                logger.error(f"ğŸ“‹ âŒ ideaè¯„ä¼°å¤±è´¥: {str(idea_result)}")
                logger.error(f"ğŸ“‹ âŒ ideaè¯„ä¼°å¼‚å¸¸ç±»å‹: {type(idea_result)}")
                idea_result = None
            else:
                logger.info(f"ğŸ“‹ âœ… ideaè¯„ä¼°æˆåŠŸ: {idea_result.get('overall_score', 'æœªçŸ¥')}")
            
            if isinstance(ui_result, Exception):
                logger.error(f"ğŸ“‹ âŒ uiè¯„ä¼°å¤±è´¥: {str(ui_result)}")
                logger.error(f"ğŸ“‹ âŒ uiè¯„ä¼°å¼‚å¸¸ç±»å‹: {type(ui_result)}")
                ui_result = None
            else:
                logger.info(f"ğŸ“‹ âœ… UIè¯„ä¼°æˆåŠŸ: {ui_result.get('overall_score', 'æœªçŸ¥')}")
                
            if isinstance(code_result, Exception):
                logger.error(f"ğŸ“‹ âŒ codeè¯„ä¼°å¤±è´¥: {str(code_result)}")
                logger.error(f"ğŸ“‹ âŒ codeè¯„ä¼°å¼‚å¸¸ç±»å‹: {type(code_result)}")
                code_result = None
            else:
                logger.info(f"ğŸ“‹ âœ… ä»£ç è¯„ä¼°æˆåŠŸ: {code_result.get('overall_score', 'æœªçŸ¥')}")
            
            # èšåˆè¯„åˆ†
            logger.info("ğŸ“‹ ğŸ“Š å¼€å§‹èšåˆè¯„åˆ†...")
            evaluation_results = {
                "idea": idea_result or {"overall_score": 0, "diagnoses": [], "resources": [], "feedback": "Ideaè¯„ä¼°å¤±è´¥"},
                "ui": ui_result or {"overall_score": 0, "diagnoses": [], "resources": [], "feedback": "UIè¯„ä¼°å¤±è´¥"},
                "code": code_result or {"overall_score": 0, "diagnoses": [], "resources": [], "feedback": "ä»£ç è¯„ä¼°å¤±è´¥"}
            }
            
            result = self.score_aggregator.aggregate_scores(evaluation_results)
            
            # æ›´æ–°è¯„ä¼°çŠ¶æ€åˆ°æ•°æ®åº“
            update_data = {
                'status': 'completed',
                'overall_score': result["overall_score"],
                'idea_score': result["score_breakdown"].idea,
                'ui_score': result["score_breakdown"].ui,
                'code_score': result["score_breakdown"].code,
                'detailed_scores': result.get("detailed_scores", {}),
                'diagnosis': result["diagnoses"],
                'resources': result["resources"],
                'exit_rules': {
                    'pass_status': result["exit_rules"].pass_status,
                    'path_update': result["exit_rules"].path_update,
                    'remedy': result["exit_rules"].remedy
                } if hasattr(result["exit_rules"], 'pass_status') else result["exit_rules"],
                'completed_at': datetime.utcnow(),
                'updated_at': datetime.utcnow()
            }
            
            self.db_service.update_assessment_run(assessment_id, update_data)
            
            logger.info(f"ğŸ“‹ ğŸ‰ è¯„ä¼°å®Œæˆå¹¶ä¿å­˜: {assessment_id}, æ€»åˆ†: {result['overall_score']}")
            
            # ğŸ†• é›†æˆå­¦ä¹ è·¯å¾„æ¨èç³»ç»Ÿï¼ˆå¯é€šè¿‡é…ç½®å¼€å…³æ§åˆ¶ï¼‰
            if path_config.enable_path_integration:
                await self._update_learning_path(assessment_id, assessment_run)
            else:
                logger.info(f"ğŸ“‹ â„¹ï¸ å­¦ä¹ è·¯å¾„é›†æˆå·²ç¦ç”¨ï¼Œè·³è¿‡è·¯å¾„æ›´æ–°: {assessment_id}")
            
        except Exception as e:
            # å¤„ç†è¯„ä¼°å¼‚å¸¸
            logger.error(f"ğŸ“‹ âŒ è¯„ä¼°æ‰§è¡Œå¤±è´¥: {assessment_id}, é”™è¯¯: {str(e)}")
            
            try:
                # æ›´æ–°æ•°æ®åº“ä¸­çš„é”™è¯¯çŠ¶æ€
                self.db_service.update_assessment_run(assessment_id, {
                    'status': 'failed',
                    'error_message': str(e),
                    'updated_at': datetime.utcnow()
                })
            except Exception as save_error:
                logger.error(f"ğŸ“‹ âŒ ä¿å­˜é”™è¯¯çŠ¶æ€å¤±è´¥: {str(save_error)}")
    
    async def _update_learning_path(self, assessment_id: str, assessment_run):
        """
        ğŸ†• æ›´æ–°å­¦ä¹ è·¯å¾„è¿›åº¦
        
        å½“è¯„ä¼°å®Œæˆåï¼Œè‡ªåŠ¨è°ƒç”¨å­¦ä¹ è·¯å¾„æœåŠ¡æ¥ï¼š
        1. æ›´æ–°å­¦ç”Ÿçš„èŠ‚ç‚¹è¿›åº¦
        2. æ ¹æ®è¯„ä¼°ç»“æœæ¨èä¸‹ä¸€æ­¥è·¯å¾„
        """
        try:
            student_id = assessment_run.student_id
            
            # ä»è¯„ä¼°ç»“æœä¸­æ¨æ–­å½“å‰å­¦ä¹ çš„èŠ‚ç‚¹
            current_node_id = self._infer_current_node_from_db(assessment_run)
            
            # æ„å»ºè¯„ä¼°ç»“æœæ•°æ®
            assessment_result = {
                "overall_score": float(assessment_run.overall_score) if assessment_run.overall_score else 0,
                "breakdown": {
                    "idea": float(assessment_run.idea_score) if assessment_run.idea_score else 0,
                    "ui": float(assessment_run.ui_score) if assessment_run.ui_score else 0,
                    "code": float(assessment_run.code_score) if assessment_run.code_score else 0
                },
                "diagnosis": assessment_run.diagnosis or [],
                "exit_rules": assessment_run.exit_rules or {}
            }
            
            # ç¡®å®šèŠ‚ç‚¹çŠ¶æ€
            overall_score_val = float(assessment_run.overall_score) if assessment_run.overall_score else 0
            if overall_score_val >= 60:  # é€šè¿‡é—¨æ§›
                node_status = NodeStatus.COMPLETED
                logger.info(f"âœ… èŠ‚ç‚¹é€šè¿‡: {current_node_id} (å¾—åˆ†: {overall_score_val}åˆ† >= 60åˆ†)")
            else:
                node_status = NodeStatus.FAILED
                logger.info(f"âŒ èŠ‚ç‚¹æœªé€šè¿‡: {current_node_id} (å¾—åˆ†: {overall_score_val}åˆ† < 60åˆ†) - éœ€è¦é™çº§é‡ä¿®")
            
            logger.info(f"ğŸ“šğŸ¤– å¼€å§‹æ›´æ–°å­¦ä¹ è·¯å¾„: {student_id} -> {current_node_id} -> {node_status.value} (å¾—åˆ†: {overall_score_val}åˆ†)")
            
            # æ›´æ–°å­¦ç”Ÿè¿›åº¦
            await self.learning_path_service.update_student_progress(
                student_id=student_id,
                node_id=current_node_id,
                status=node_status,
                assessment_result=assessment_result
            )
            
            # å¦‚æœèŠ‚ç‚¹å®Œæˆæˆ–å¤±è´¥ï¼Œéƒ½ç”Ÿæˆè·¯å¾„æ¨è
            # COMPLETED: å†³å®šå‡çº§/ä¿æŒ/è¿›å…¥ä¸‹ä¸€èŠ‚ç‚¹
            # FAILED: å†³å®šé™çº§é‡ä¿®æˆ–ä¿æŒéš¾åº¦é‡ä¿®
            if node_status in [NodeStatus.COMPLETED, NodeStatus.FAILED]:
                recommendation = await self.learning_path_service.recommend_next_step(
                    student_id=student_id,
                    assessment_result=assessment_result
                )
                logger.info(f"ğŸ“šğŸ¤– è·¯å¾„æ¨èå·²ç”Ÿæˆ: {student_id} -> {recommendation.recommended_channel.value}é€šé“ -> {recommendation.next_node_id}, å†³ç­–: {recommendation.decision.value}")
            
            logger.info(f"ğŸ“šğŸ¤– âœ… å­¦ä¹ è·¯å¾„æ›´æ–°æˆåŠŸ: {assessment_id}")
            
        except Exception as e:
            # å­¦ä¹ è·¯å¾„æ›´æ–°å¤±è´¥ä¸åº”è¯¥å½±å“è¯„ä¼°ç»“æœ
            logger.warning(f"ğŸ“šğŸ¤– âš ï¸ å­¦ä¹ è·¯å¾„æ›´æ–°å¤±è´¥ï¼Œä½†è¯„ä¼°å·²å®Œæˆ: {assessment_id}, é”™è¯¯: {str(e)}")
    
    def _infer_current_node(self, deliverables) -> str:
        """
        ğŸ†• æ ¹æ®æäº¤ç‰©æ¨æ–­å½“å‰å­¦ä¹ èŠ‚ç‚¹
        
        åŸºäºå­¦ç”Ÿæäº¤çš„ä½œä¸šå†…å®¹ï¼Œæ™ºèƒ½æ¨æ–­å½“å‰æ­£åœ¨å­¦ä¹ çš„è¯¾ç¨‹èŠ‚ç‚¹
        """
        
        # åˆ†ææäº¤ç‰©å†…å®¹ç‰¹å¾
        idea_text = deliverables.idea_text.lower() if deliverables.idea_text else ""
        code_snippets = " ".join(deliverables.code_snippets).lower() if deliverables.code_snippets else ""
        has_ui_images = len(deliverables.ui_images) > 0 if deliverables.ui_images else False
        
        # èŠ‚ç‚¹å…³é”®è¯æ˜ å°„
        node_keywords = {
            "api_calling": ["api", "è°ƒç”¨", "æ¥å£", "è¯·æ±‚", "response", "http", "rest"],
            "model_deployment": ["æ¨¡å‹", "éƒ¨ç½²", "docker", "ollama", "éƒ¨ç½²", "æ¨ç†", "æœåŠ¡"],
            "no_code_ai": ["dify", "é›¶ä»£ç ", "æ— ä»£ç ", "flow", "å·¥ä½œæµ", "é…ç½®"],
            "rag_system": ["rag", "æ£€ç´¢", "å‘é‡", "faiss", "embedding", "çŸ¥è¯†åº“", "æ–‡æ¡£"],
            "ui_design": ["ui", "ç•Œé¢", "è®¾è®¡", "ç”¨æˆ·ä½“éªŒ", "åŸå‹", "äº¤äº’"],
            "frontend_dev": ["å‰ç«¯", "react", "vue", "html", "css", "javascript", "ç»„ä»¶"],
            "backend_dev": ["åç«¯", "api", "æ•°æ®åº“", "æœåŠ¡å™¨", "fastapi", "flask", "æ¥å£"]
        }
        
        # è®¡ç®—æ¯ä¸ªèŠ‚ç‚¹çš„åŒ¹é…å¾—åˆ†
        node_scores = {}
        for node_id, keywords in node_keywords.items():
            score = 0
            for keyword in keywords:
                if keyword in idea_text:
                    score += 2  # ideaä¸­çš„å…³é”®è¯æƒé‡æ›´é«˜
                if keyword in code_snippets:
                    score += 3  # ä»£ç ä¸­çš„å…³é”®è¯æƒé‡æœ€é«˜
            
            # UIç›¸å…³çš„ç‰¹æ®Šå¤„ç†
            if node_id == "ui_design" and has_ui_images:
                score += 5
            
            node_scores[node_id] = score
        
        # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„èŠ‚ç‚¹
        if node_scores:
            best_node = max(node_scores, key=node_scores.get)
            max_score = node_scores[best_node]
            
            # å¦‚æœå¾—åˆ†è¿‡ä½ï¼Œä½¿ç”¨é»˜è®¤æ¨æ–­é€»è¾‘
            if max_score < 2:
                return self._default_node_inference()
            
            logger.info(f"ğŸ“šğŸ¤– èŠ‚ç‚¹æ¨æ–­: {best_node} (å¾—åˆ†: {max_score})")
            return best_node
        
        return self._default_node_inference()
    
    def _default_node_inference(self) -> str:
        """é»˜è®¤èŠ‚ç‚¹æ¨æ–­é€»è¾‘"""
        # ç®€å•ç­–ç•¥ï¼šè¿”å›æœ€å¸¸è§çš„èŠ‚ç‚¹æˆ–è€…æŒ‰é¡ºåºæ¨æ–­
        return "api_calling"  # é»˜è®¤ä¸ºç¬¬ä¸€ä¸ªèŠ‚ç‚¹
    
    def _infer_current_node_from_db(self, assessment_run) -> str:
        """ä»æ•°æ®åº“è®°å½•æ¨æ–­å½“å‰èŠ‚ç‚¹"""
        # ä½¿ç”¨èŠ‚ç‚¹IDå­—æ®µï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨é»˜è®¤æ¨æ–­
        if assessment_run.node_id:
            return assessment_run.node_id
        return self._default_node_inference()
    
    def _get_task_info(self, node_id: str, channel: str) -> Dict[str, Any]:
        """è·å–ä»»åŠ¡ä¿¡æ¯"""
        try:
            # ä»å­¦ä¹ è·¯å¾„æœåŠ¡è·å–ä»»åŠ¡ä¿¡æ¯
            learning_path = self.learning_path_service.get_learning_path()
            if not learning_path:
                logger.warning(f"æ— æ³•è·å–å­¦ä¹ è·¯å¾„ï¼Œè¿”å›ç©ºä»»åŠ¡ä¿¡æ¯")
                return {
                    "requirements": [],
                    "deliverables": [],
                    "description": ""
                }
            
            # æŸ¥æ‰¾èŠ‚ç‚¹
            current_node = None
            for node in learning_path.nodes:
                if node.id == node_id:
                    current_node = node
                    break
            
            if not current_node:
                logger.warning(f"æœªæ‰¾åˆ°èŠ‚ç‚¹: {node_id}")
                return {
                    "requirements": [],
                    "deliverables": [],
                    "description": ""
                }
            
            # è·å–é€šé“ä»»åŠ¡ä¿¡æ¯
            from ..models.learning_path import Channel as ChannelEnum
            channel_enum = ChannelEnum[channel]
            channel_task = current_node.channel_tasks.get(channel_enum, {})
            
            task_info = {
                "description": channel_task.get("task", ""),
                "requirements": channel_task.get("requirements", []),
                "deliverables": channel_task.get("deliverables", [])
            }
            
            logger.info(f"âœ… æˆåŠŸè·å–ä»»åŠ¡ä¿¡æ¯: {node_id} -> {channel}")
            logger.info(f"    ä»»åŠ¡è¦æ±‚: {len(task_info['requirements'])} é¡¹")
            logger.info(f"    æäº¤è¦æ±‚: {len(task_info['deliverables'])} é¡¹")
            return task_info
            
        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡ä¿¡æ¯å¤±è´¥: {str(e)}")
            return {
                "requirements": [],
                "deliverables": [],
                "description": ""
            }
    
    def _check_deliverables_completeness(self, evaluation_data: Dict[str, Any], 
                                         task_requirements: List[str], 
                                         task_deliverables: List[str]) -> Dict[str, Any]:
        """æ£€æŸ¥æäº¤ææ–™çš„å®Œæ•´æ€§"""
        missing_deliverables = []
        has_code = bool(evaluation_data.get("code_repo") or evaluation_data.get("code_snippets"))
        has_ui = bool(evaluation_data.get("ui_images"))
        has_idea = bool(evaluation_data.get("idea_text"))
        
        # æ£€æŸ¥å¸¸è§çš„æäº¤è¦æ±‚
        for deliverable in task_deliverables:
            deliverable_lower = deliverable.lower()
            
            # ä»£ç ç›¸å…³
            if any(keyword in deliverable_lower for keyword in ["ä»£ç ", "ç¨‹åº", "å®ç°", "æºç ", "repository", "repo"]):
                if not has_code:
                    missing_deliverables.append(deliverable)
            
            # UIç›¸å…³
            elif any(keyword in deliverable_lower for keyword in ["ui", "ç•Œé¢", "è®¾è®¡", "åŸå‹", "å›¾ç‰‡"]):
                if not has_ui:
                    missing_deliverables.append(deliverable)
            
            # åˆ›æ„ç›¸å…³
            elif any(keyword in deliverable_lower for keyword in ["åˆ›æ„", "æƒ³æ³•", "é¡¹ç›®æè¿°", "idea"]):
                if not has_idea:
                    missing_deliverables.append(deliverable)
        
        completeness_info = {
            "missing_deliverables": missing_deliverables,
            "has_code": has_code,
            "has_ui": has_ui,
            "has_idea": has_idea,
            "is_complete": len(missing_deliverables) == 0
        }
        
        if missing_deliverables:
            logger.warning(f"âš ï¸ æäº¤ææ–™ä¸å®Œæ•´ï¼Œç¼ºå¤±: {missing_deliverables}")
        else:
            logger.info(f"âœ… æäº¤ææ–™å®Œæ•´")
        
        return completeness_info

    def _prepare_evaluation_data_from_db(self, assessment_run) -> Dict[str, Any]:
        """ä»æ•°æ®åº“è®°å½•å‡†å¤‡è¯„ä¼°æ•°æ®"""
        logger.info(f"ğŸ“‹ ğŸ” å¼€å§‹å‡†å¤‡è¯„ä¼°æ•°æ®ï¼Œè¯„ä¼°ID: {assessment_run['run_id']}")
        
        # ä»å…³è”çš„æäº¤è®°å½•è·å–è¯¦ç»†ä¿¡æ¯
        submissions = self.db_service.get_submissions_by_assessment_run(assessment_run['run_id'])
        logger.info(f"ğŸ“‹ ğŸ“Š æ‰¾åˆ° {len(submissions)} æ¡æäº¤è®°å½•")
        
        # ğŸ”¥ è·å–ä»»åŠ¡ä¿¡æ¯
        node_id = assessment_run.get('node_id')
        channel = assessment_run.get('channel')
        task_info = self._get_task_info(node_id, channel)
        logger.info(f"ğŸ“‹ ğŸ“ ä»»åŠ¡ä¿¡æ¯: {node_id} -> {channel}é€šé“")
        logger.info(f"    ä»»åŠ¡è¦æ±‚: {task_info.get('requirements', [])}")
        logger.info(f"    æäº¤è¦æ±‚: {task_info.get('deliverables', [])}")
        
        # æ„å»ºè¯„ä¼°æ•°æ®
        evaluation_data = {
            # Ideaç›¸å…³æ•°æ®
            "idea_text": "",
            "project_name": "é¡¹ç›®",
            "technical_stack": [],
            "target_users": "ç”¨æˆ·",
            "core_features": [],
            
            # UIç›¸å…³æ•°æ®
            "ui_images": [],
            "design_tool": "",
            "design_system": "",
            "color_palette": [],
            "prototype_url": "",
            
            # ä»£ç ç›¸å…³æ•°æ®
            "code_repo": "",
            "language": "python",
            "framework": "æœªæŒ‡å®š",
            "lines_of_code": 0,
            "test_coverage": 0.0,
            "code_snippets": [],
            
            # ğŸ”¥ æ–°å¢ï¼šä»»åŠ¡ä¿¡æ¯
            "task_requirements": task_info.get('requirements', []),
            "task_deliverables": task_info.get('deliverables', []),
            "task_description": task_info.get('description', ''),
            "node_id": node_id,
            "channel": channel
        }
        
        # ä»æäº¤è®°å½•ä¸­æå–æ•°æ®
        for i, submission in enumerate(submissions):
            logger.info(f"ğŸ“‹ ğŸ“ å¤„ç†ç¬¬ {i+1} æ¡æäº¤è®°å½•:")
            logger.info(f"    æäº¤ID: {submission['submission_id']}")
            logger.info(f"    æäº¤ç±»å‹: {submission['submission_type']}")
            logger.info(f"    æ–‡ä»¶è·¯å¾„: {submission['file_path']}")
            logger.info(f"    åˆ›æ„æ–‡æœ¬é•¿åº¦: {len(submission['idea_text']) if submission['idea_text'] else 0}")
            logger.info(f"    ä»£ç ä»“åº“: {submission['code_repo']}")
            logger.info(f"    ä»£ç ç‰‡æ®µæ•°é‡: {len(submission['code_snippets']) if submission['code_snippets'] else 0}")
            
            if submission['idea_text']:
                evaluation_data["idea_text"] = submission['idea_text']
                logger.info(f"    âœ… è®¾ç½®åˆ›æ„æ–‡æœ¬: {submission['idea_text'][:100]}...")
            if submission['ui_images']:
                evaluation_data["ui_images"] = submission['ui_images']
                logger.info(f"    âœ… è®¾ç½®UIå›¾ç‰‡: {len(submission['ui_images'])} å¼ ")
            if submission['code_repo']:
                evaluation_data["code_repo"] = submission['code_repo']
                logger.info(f"    âœ… è®¾ç½®ä»£ç ä»“åº“: {submission['code_repo']}")
            if submission['code_snippets']:
                evaluation_data["code_snippets"] = submission['code_snippets']
                logger.info(f"    âœ… è®¾ç½®ä»£ç ç‰‡æ®µ: {len(submission['code_snippets'])} ä¸ªæ–‡ä»¶")
                if isinstance(submission['code_snippets'], list):
                    for i, content in enumerate(submission['code_snippets'][:2]):  # åªæ˜¾ç¤ºå‰2ä¸ªæ–‡ä»¶
                        logger.info(f"      æ–‡ä»¶ {i+1}: (é•¿åº¦: {len(content)})")
                elif isinstance(submission['code_snippets'], dict):
                    for file_name, content in list(submission['code_snippets'].items())[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªæ–‡ä»¶
                        logger.info(f"      æ–‡ä»¶: {file_name} (é•¿åº¦: {len(content)})")
        
        logger.info(f"ğŸ“‹ ğŸ“Š æœ€ç»ˆè¯„ä¼°æ•°æ®:")
        logger.info(f"    åˆ›æ„æ–‡æœ¬: {evaluation_data['idea_text'][:50] if evaluation_data['idea_text'] else 'None'}...")
        logger.info(f"    ä»£ç ä»“åº“: {evaluation_data['code_repo']}")
        logger.info(f"    ä»£ç ç‰‡æ®µæ•°é‡: {len(evaluation_data['code_snippets'])}")
        if evaluation_data['code_snippets']:
            if isinstance(evaluation_data['code_snippets'], list):
                logger.info(f"    ä»£ç ç‰‡æ®µç±»å‹: åˆ—è¡¨ ({len(evaluation_data['code_snippets'])} ä¸ª)")
            elif isinstance(evaluation_data['code_snippets'], dict):
                logger.info(f"    ä»£ç ç‰‡æ®µæ–‡ä»¶: {list(evaluation_data['code_snippets'].keys())}")
        else:
            logger.info(f"    ä»£ç ç‰‡æ®µæ–‡ä»¶: None")
        
        # ğŸ”¥ æ£€æŸ¥æäº¤ææ–™å®Œæ•´æ€§
        completeness_info = self._check_deliverables_completeness(
            evaluation_data, 
            task_info.get('requirements', []),
            task_info.get('deliverables', [])
        )
        
        # å°†å®Œæ•´æ€§ä¿¡æ¯æ·»åŠ åˆ°è¯„ä¼°æ•°æ®ä¸­
        evaluation_data["completeness_info"] = completeness_info
        
        # å¦‚æœæœ‰ç¼ºå¤±çš„ææ–™ï¼Œè®°å½•è­¦å‘Š
        if not completeness_info["is_complete"]:
            logger.warning(f"âš ï¸âš ï¸âš ï¸ æäº¤ææ–™ä¸å®Œæ•´ï¼ç¼ºå¤±é¡¹: {completeness_info['missing_deliverables']}")
            logger.warning(f"    å­˜åœ¨ä»£ç : {completeness_info['has_code']}")
            logger.warning(f"    å­˜åœ¨UI: {completeness_info['has_ui']}")
            logger.warning(f"    å­˜åœ¨åˆ›æ„: {completeness_info['has_idea']}")
        
        return evaluation_data

    def _prepare_evaluation_data(self, assessment: Assessment) -> Dict[str, Any]:
        """å‡†å¤‡è¯„ä¼°æ•°æ®ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰"""
        deliverables = assessment.deliverables
        return {
            # Ideaç›¸å…³æ•°æ®
            "idea_text": deliverables.idea_text,
            "project_name": "é¡¹ç›®",
            "technical_stack": [],
            "target_users": "ç”¨æˆ·",
            "core_features": [],
            
            # UIç›¸å…³æ•°æ®
            "ui_images": deliverables.ui_images,
            "design_tool": "",
            "design_system": "",
            "color_palette": [],
            "prototype_url": "",
            
            # ä»£ç ç›¸å…³æ•°æ®
            "code_repo": deliverables.code_repo,
            "language": "python",
            "framework": "æœªæŒ‡å®š",
            "lines_of_code": 0,
            "test_coverage": 0.0,
            "code_snippets": deliverables.code_snippets
        }
    
    def _parse_deliverables(self, deliverables: Dict[str, Any]) -> Deliverables:
        """è§£ææäº¤ç‰©æ•°æ®"""
        return Deliverables(
            idea_text=deliverables.get("idea_text", ""),
            ui_images=deliverables.get("ui_images", []),
            code_repo=deliverables.get("code_repo"),
            code_snippets=deliverables.get("code_snippets", [])
        )
    
    async def export_path_rules(self, assessment_id: str) -> Dict[str, Any]:
        """
        å¯¼å‡ºå‡†å‡ºè§„åˆ™åˆ°å­¦ä¹ è·¯å¾„å¼•æ“
        
        Args:
            assessment_id: è¯„ä¼°ID
            
        Returns:
            å¯¼å‡ºç»“æœ
        """
        # ä»æ•°æ®åº“è·å–è¯„ä¼°è®°å½•
        assessment_run = self.db_service.get_assessment_run(assessment_id)
        if not assessment_run:
            raise AssessmentServiceError(f"è¯„ä¼°è®°å½•ä¸å­˜åœ¨: {assessment_id}")
        
        if assessment_run['status'] != 'completed':
            raise AssessmentServiceError(f"è¯„ä¼°å°šæœªå®Œæˆ: {assessment_id}")
        
        # è¿™é‡Œåº”è¯¥è°ƒç”¨å­¦ä¹ è·¯å¾„å¼•æ“çš„API
        # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿç»“æœ
        path_rule_id = f"rule_{str(uuid.uuid4())[:8]}"
        
        logger.info(f"å‡†å‡ºè§„åˆ™å·²å¯¼å‡ºåˆ°è·¯å¾„å¼•æ“: {assessment_id} -> {path_rule_id}")
        
        return {
            "synced": True,
            "path_engine_ref": path_rule_id,
            "assessment_id": assessment_id,
            "export_time": datetime.now().isoformat()
        }


class AssessmentServiceError(Exception):
    """è¯„ä¼°æœåŠ¡é”™è¯¯"""
    pass